{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:44.717382Z",
     "start_time": "2019-10-25T20:57:42.237088Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import sklearn\n",
    "from skmultilearn.ensemble import MajorityVotingClassifier\n",
    "from sklearn import linear_model, svm, naive_bayes, neighbors, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:44.810159Z",
     "start_time": "2019-10-25T20:57:44.720670Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:50.538916Z",
     "start_time": "2019-10-25T20:57:45.297766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/greenapple/project3\n",
      "Installing collected packages: src\n",
      "  Found existing installation: src 0.1.0\n",
      "    Uninstalling src-0.1.0:\n",
      "      Successfully uninstalled src-0.1.0\n",
      "  Running setup.py develop for src\n",
      "Successfully installed src\n"
     ]
    }
   ],
   "source": [
    "!pip install --editable .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:50.669197Z",
     "start_time": "2019-10-25T20:57:50.541452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unpickle data \n",
    "with open('/users/greenapple/project3/data/processed/house_bal.pkl', 'rb') as f:\n",
    "    house_bal = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:50.791428Z",
     "start_time": "2019-10-25T20:57:50.672093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id_list</th>\n",
       "      <th>y</th>\n",
       "      <th>y_name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>630</th>\n",
       "      <th>631</th>\n",
       "      <th>632</th>\n",
       "      <th>633</th>\n",
       "      <th>634</th>\n",
       "      <th>635</th>\n",
       "      <th>636</th>\n",
       "      <th>637</th>\n",
       "      <th>638</th>\n",
       "      <th>639</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>b'--ZhevVpy1s'</td>\n",
       "      <td>375</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>117</td>\n",
       "      <td>35</td>\n",
       "      <td>163</td>\n",
       "      <td>90</td>\n",
       "      <td>198</td>\n",
       "      <td>103</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>9</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>72</td>\n",
       "      <td>44</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>b'-2hQKCE-oTI'</td>\n",
       "      <td>53</td>\n",
       "      <td>footsteps</td>\n",
       "      <td>30</td>\n",
       "      <td>162</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>216</td>\n",
       "      <td>116</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>109</td>\n",
       "      <td>50</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "      <td>154</td>\n",
       "      <td>42</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>b'-3pPrlCm6gg'</td>\n",
       "      <td>198</td>\n",
       "      <td>clarinet</td>\n",
       "      <td>179</td>\n",
       "      <td>190</td>\n",
       "      <td>122</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>43</td>\n",
       "      <td>97</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>b'-70wVF5u-gg'</td>\n",
       "      <td>366</td>\n",
       "      <td>chopping_food</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>186</td>\n",
       "      <td>34</td>\n",
       "      <td>87</td>\n",
       "      <td>250</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>144</td>\n",
       "      <td>63</td>\n",
       "      <td>110</td>\n",
       "      <td>255</td>\n",
       "      <td>139</td>\n",
       "      <td>138</td>\n",
       "      <td>59</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>b'-ASYwidRD7M'</td>\n",
       "      <td>43</td>\n",
       "      <td>snoring</td>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>144</td>\n",
       "      <td>84</td>\n",
       "      <td>223</td>\n",
       "      <td>68</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>78</td>\n",
       "      <td>153</td>\n",
       "      <td>65</td>\n",
       "      <td>208</td>\n",
       "      <td>207</td>\n",
       "      <td>200</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     video_id_list    y         y_name    0    1    2   3    4    5    6  ...  \\\n",
       "5   b'--ZhevVpy1s'  375     toothbrush  117   35  163  90  198  103   63  ...   \n",
       "20  b'-2hQKCE-oTI'   53      footsteps   30  162   44   7  216  116  206  ...   \n",
       "28  b'-3pPrlCm6gg'  198       clarinet  179  190  122  19    0  114  255  ...   \n",
       "63  b'-70wVF5u-gg'  366  chopping_food    0  114  186  34   87  250   58  ...   \n",
       "82  b'-ASYwidRD7M'   43        snoring   53  100  144  84  223   68   95  ...   \n",
       "\n",
       "    630  631  632  633  634  635  636  637  638  639  \n",
       "5     0    1  202    9  116    0  247   72   44  166  \n",
       "20  213  109   50   88   19   46   54  154   42  211  \n",
       "28   58   15  207    0  108   43   97   57   42    0  \n",
       "63    0  122  144   63  110  255  139  138   59  154  \n",
       "82   56   78  153   65  208  207  200  255  255   66  \n",
       "\n",
       "[5 rows x 643 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:50.874837Z",
     "start_time": "2019-10-25T20:57:50.794861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45717, 643)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:50.983255Z",
     "start_time": "2019-10-25T20:57:50.877069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(house_bal.y_name.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:51.092498Z",
     "start_time": "2019-10-25T20:57:50.986869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech            4042\n",
       "music             3781\n",
       "laughter          3772\n",
       "snoring           3370\n",
       "vacuum_cleaner    3054\n",
       "typing            2644\n",
       "dishes_pots       2560\n",
       "frying_food       2102\n",
       "blender           1884\n",
       "toilet_flush      1882\n",
       "door              1868\n",
       "whoop             1736\n",
       "footsteps         1492\n",
       "baby_cry          1414\n",
       "screeming         1116\n",
       "whispering         972\n",
       "clarinet           960\n",
       "crying             918\n",
       "microwave          894\n",
       "television         866\n",
       "hair_dryer         772\n",
       "video_games        592\n",
       "shaving            552\n",
       "bathtab            472\n",
       "water_tap          458\n",
       "chopping_food      410\n",
       "meow               388\n",
       "dog                358\n",
       "purr               304\n",
       "toothbrush          84\n",
       "Name: y_name, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_bal.y_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:51.190729Z",
     "start_time": "2019-10-25T20:57:51.096720Z"
    }
   },
   "outputs": [],
   "source": [
    "ten_class_list = [\n",
    "    'speech',\n",
    "    'music',\n",
    "    'clarinet',\n",
    "    'water_tap',\n",
    "    'footsteps',\n",
    "    'microwave',\n",
    "    'door',\n",
    "    'blender',\n",
    "    'vacuum_cleaner',\n",
    "    'meow'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:51.300253Z",
     "start_time": "2019-10-25T20:57:51.194149Z"
    }
   },
   "outputs": [],
   "source": [
    "house_10_classes = house_bal.loc[house_bal.y_name.isin(ten_class_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:51.425881Z",
     "start_time": "2019-10-25T20:57:51.305294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech            4042\n",
       "music             3781\n",
       "vacuum_cleaner    3054\n",
       "blender           1884\n",
       "door              1868\n",
       "footsteps         1492\n",
       "clarinet           960\n",
       "microwave          894\n",
       "water_tap          458\n",
       "meow               388\n",
       "Name: y_name, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_10_classes.y_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:51.556604Z",
     "start_time": "2019-10-25T20:57:51.436871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign features X and target y\n",
    "X = house_10_classes[house_10_classes.columns[3:643]]\n",
    "y = house_10_classes.y_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:51.717762Z",
     "start_time": "2019-10-25T20:57:51.567822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15056, 640), (15056,), (3765, 640), (3765,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:57:53.502447Z",
     "start_time": "2019-10-25T20:57:53.423745Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import sklearn\n",
    "from datetime import datetime\n",
    "\n",
    "from src.models.time_best_fit import time_best_fit\n",
    "\n",
    "# Function for finding the best parameters\n",
    "def train_fit_time(model,\n",
    "                   param_distributions,\n",
    "                   transformer,\n",
    "                   X_train,\n",
    "                   X_test,\n",
    "                   y_train,\n",
    "                   y_test,\n",
    "                   CV):\n",
    "\n",
    "    '''Function searches for the best model paramenters through a cross-validation on the train set\n",
    "    and returns results of test set fit.\n",
    "\n",
    "    Args:\n",
    "        model - supervised learning classifier\n",
    "        param_grid (dict) - set of model specific parameters\n",
    "        transformer - data transformer\n",
    "        X_train (DataFrame) - training data set\n",
    "        y_train (DataFrame) - training target set\n",
    "        X_test (DataFrame) - test data set\n",
    "        y_test (DataFrame) - test traget set\n",
    "        CV (int) - number of cross-validation folds\n",
    "\n",
    "    Returns:\n",
    "        dictionary with the following keys:\n",
    "            train_score\n",
    "            test_score\n",
    "            time (sec) - how long this function runs for\n",
    "            time_best_fit (sec)\n",
    "            params\n",
    "            estimator\n",
    "            test_proba\n",
    "            y_hat\n",
    "            all_scores\n",
    "        model\n",
    "    '''\n",
    "    # Time the function: record start time\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    pipe = Pipeline([('transformer', transformer), ('model', model)])\n",
    "\n",
    "    # Parameter grid\n",
    "    grid = RandomizedSearchCV(pipe, param_distributions, cv=CV, scoring='f1_micro', refit=True, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Time the function: record end time\n",
    "    end_time = datetime.now()\n",
    "    time = (end_time - start_time).total_seconds()\n",
    "\n",
    "    # Parameters and scores\n",
    "    params_scores_pred = {\n",
    "        'best_train_score':grid.best_score_,\n",
    "        'best_test_score': grid.score(X_test, y_test),\n",
    "        'time_sec': time,\n",
    "        'time_best_fit_sec': time_best_fit(grid, X_train, y_train),\n",
    "        'best_params':grid.best_params_,\n",
    "        'best_estimator':grid.best_estimator_,\n",
    "        'best_test_proba': grid.predict_proba(X_test),\n",
    "        'best_y_hat': grid.predict(X_test),\n",
    "        'all_scores': grid.cv_results_\n",
    "\n",
    "    }\n",
    "\n",
    "    return params_scores_pred, grid\n",
    "\n",
    "\n",
    "# Function for estimating the run time for the best fit\n",
    "def time_best_fit(grid, X_train, y_train):\n",
    "\n",
    "    '''Function returns the time of fit for the best parameters found by GridSearchCV.\n",
    "\n",
    "    Args:\n",
    "       best model from train_fit_time() - grid.\n",
    "\n",
    "    Returns:\n",
    "       time of fit in seconds.\n",
    "    '''\n",
    "\n",
    "    # Time the function: record start time\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    pipe = grid.best_estimator_\n",
    "\n",
    "    # Time the function: record start time\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # Fit\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Time the function: record end time\n",
    "    end_time = datetime.now()\n",
    "    fit_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "    if int(fit_time) < 5.0:\n",
    "        time = 0\n",
    "        for i in range(4):\n",
    "            start_time_ = datetime.now()\n",
    "            pipe.fit(X_train, y_train)\n",
    "            start_time_ = datetime.now()\n",
    "            time = (end_time - start_time).total_seconds()\n",
    "            time += time\n",
    "        fit_time = (time + fit_time)/5\n",
    "\n",
    "    return fit_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T17:35:29.887767Z",
     "start_time": "2019-10-19T17:35:29.883261Z"
    }
   },
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fldr = '/home/ubuntu/project3_aws/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and fit logistic regression with  RandomizedSearchCV:  1st set of parameteres\n",
    "# from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = LogisticRegression(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver = ['liblinear', 'saga']\n",
    "\n",
    "param_distributions = dict(\n",
    "        model__C = C, \n",
    "        model__penalty = penalty,\n",
    "        model__solver=solver)\n",
    "\n",
    "# Call parameter selection function\n",
    "logreg1_10_cls_scores_params, logreg1_10_cls_model = train_fit_time(model,\n",
    "                                                                               param_distributions,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "# Pickle results\n",
    "with open(os.path.join(model_fldr,'logreg1_10_cls_scores_params_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(logreg1_10_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open(os.path.join(model_fldr,'logreg1_10_cls_model_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(logreg1_10_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters and scores\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg1_10_cls_scores_params_rand.pkl'), 'rb')\n",
    "logreg1_10_cls_scores_params = pickle.load(pickling_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.6857066950053134,\n",
       " 'best_test_score': 0.6783532536520585,\n",
       " 'time_sec': 3817.727388,\n",
       " 'time_best_fit_sec': 205.980575,\n",
       " 'best_params': {'model__solver': 'saga',\n",
       "  'model__penalty': 'l1',\n",
       "  'model__C': 1.0},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                     fit_intercept=True, intercept_scaling=1,\n",
       "                                     l1_ratio=None, max_iter=100,\n",
       "                                     multi_class='warn', n_jobs=None,\n",
       "                                     penalty='l1', random_state=3, solver='saga',\n",
       "                                     tol=0.0001, verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[9.37476427e-03, 3.82529202e-05, 3.85857380e-04, ...,\n",
       "         4.54154028e-02, 1.03427812e-04, 8.03827260e-04],\n",
       "        [5.71576302e-05, 8.40852198e-09, 3.45325714e-04, ...,\n",
       "         2.86601924e-01, 3.43316316e-03, 1.15537124e-03],\n",
       "        [8.87629760e-01, 1.19224274e-04, 5.89764378e-07, ...,\n",
       "         4.77552502e-02, 2.65954600e-02, 5.54433884e-07],\n",
       "        ...,\n",
       "        [6.06707527e-03, 3.67664157e-06, 5.35112757e-02, ...,\n",
       "         8.20606658e-02, 3.40276078e-04, 2.42133123e-05],\n",
       "        [6.52404484e-04, 3.33189384e-08, 1.53000601e-04, ...,\n",
       "         6.44280103e-02, 2.46765210e-05, 9.09155013e-07],\n",
       "        [1.13236344e-03, 3.12354553e-04, 4.42479309e-04, ...,\n",
       "         7.94627892e-03, 5.33040874e-06, 1.62688862e-05]]),\n",
       " 'best_y_hat': array(['music', 'footsteps', 'blender', ..., 'music', 'music', 'music'],\n",
       "       dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([2031.3804472 ,  315.83258495,  699.27112236,  207.39307656,\n",
       "          294.04447608,  301.81527915,  568.13529305,  192.00861301,\n",
       "          296.34248905,  454.21524296]),\n",
       "  'std_fit_time': array([ 51.69289266,   9.05456224, 145.34720112,   8.43336207,\n",
       "           1.74041781,   4.47651772,  73.96800258,   6.92211936,\n",
       "           5.5924309 ,  43.2213011 ]),\n",
       "  'mean_score_time': array([0.04440536, 0.05506473, 0.05073686, 0.04828148, 0.04099097,\n",
       "         0.04759626, 0.04515734, 0.04515734, 0.04293785, 0.02622266]),\n",
       "  'std_score_time': array([0.00381219, 0.00449718, 0.0022508 , 0.0059521 , 0.00242001,\n",
       "         0.00227964, 0.00218857, 0.00224634, 0.00680033, 0.00185065]),\n",
       "  'param_model__solver': masked_array(data=['liblinear', 'saga', 'liblinear', 'saga', 'saga',\n",
       "                     'saga', 'liblinear', 'saga', 'saga', 'liblinear'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__penalty': masked_array(data=['l2', 'l1', 'l1', 'l2', 'l1', 'l1', 'l1', 'l2', 'l1',\n",
       "                     'l1'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__C': masked_array(data=[1291.5496650148827, 7.742636826811269,\n",
       "                     7.742636826811269, 21.544346900318832, 1.0,\n",
       "                     166.81005372000593, 2.7825594022071245,\n",
       "                     464.15888336127773, 2.7825594022071245,\n",
       "                     1291.5496650148827],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__solver': 'liblinear',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 1291.5496650148827},\n",
       "   {'model__solver': 'saga',\n",
       "    'model__penalty': 'l1',\n",
       "    'model__C': 7.742636826811269},\n",
       "   {'model__solver': 'liblinear',\n",
       "    'model__penalty': 'l1',\n",
       "    'model__C': 7.742636826811269},\n",
       "   {'model__solver': 'saga',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 21.544346900318832},\n",
       "   {'model__solver': 'saga', 'model__penalty': 'l1', 'model__C': 1.0},\n",
       "   {'model__solver': 'saga',\n",
       "    'model__penalty': 'l1',\n",
       "    'model__C': 166.81005372000593},\n",
       "   {'model__solver': 'liblinear',\n",
       "    'model__penalty': 'l1',\n",
       "    'model__C': 2.7825594022071245},\n",
       "   {'model__solver': 'saga',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 464.15888336127773},\n",
       "   {'model__solver': 'saga',\n",
       "    'model__penalty': 'l1',\n",
       "    'model__C': 2.7825594022071245},\n",
       "   {'model__solver': 'liblinear',\n",
       "    'model__penalty': 'l1',\n",
       "    'model__C': 1291.5496650148827}],\n",
       "  'split0_test_score': array([0.66655607, 0.6924353 , 0.66721964, 0.6924353 , 0.6924353 ,\n",
       "         0.6924353 , 0.668215  , 0.6924353 , 0.6924353 , 0.66755143]),\n",
       "  'split1_test_score': array([0.66699867, 0.68891102, 0.66699867, 0.68891102, 0.68924303,\n",
       "         0.68891102, 0.66633466, 0.68891102, 0.68891102, 0.66666667]),\n",
       "  'split2_test_score': array([0.65526403, 0.68282962, 0.65991365, 0.68282962, 0.68282962,\n",
       "         0.68282962, 0.66124211, 0.68282962, 0.68282962, 0.65991365]),\n",
       "  'split3_test_score': array([0.64385382, 0.67375415, 0.64750831, 0.67375415, 0.67375415,\n",
       "         0.67375415, 0.64651163, 0.67375415, 0.67375415, 0.64717608]),\n",
       "  'split4_test_score': array([0.66134929, 0.69026255, 0.66301097, 0.69026255, 0.69026255,\n",
       "         0.69026255, 0.66201396, 0.69026255, 0.69026255, 0.66267863]),\n",
       "  'mean_test_score': array([0.65880712, 0.68564028, 0.66093252, 0.68564028, 0.6857067 ,\n",
       "         0.68564028, 0.6608661 , 0.68564028, 0.68564028, 0.66079968]),\n",
       "  'std_test_score': array([0.00859935, 0.00674372, 0.00723692, 0.00674372, 0.00677715,\n",
       "         0.00674372, 0.00763409, 0.00674372, 0.00674372, 0.00734712]),\n",
       "  'rank_test_score': array([10,  2,  7,  2,  1,  2,  8,  2,  2,  9], dtype=int32)}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg1_10_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg1_10_cls_model_rand.pkl'), 'rb')\n",
    "logreg1_10_cls_model = pickle.load(pickling_out)\n",
    "logreg1_10_cls_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and fit logistic regression with  RandomizedSearchCV: 2nd set of parameteres\n",
    "# from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = LogisticRegression(random_state=3, multi_class='multinomial', solver='saga')\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "penalty = ['elasticnet']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver = 'saga'\n",
    "multiclass='multinomial'\n",
    "l1_ratio = list(np.arange(0, 1, 0.1))\n",
    "\n",
    "param_distributions = dict(\n",
    "        model__C = C, \n",
    "        model__penalty = penalty,\n",
    "        model__l1_ratio=l1_ratio)\n",
    "\n",
    "\n",
    "# Call parameter selection function\n",
    "logreg2_10_cls_scores_params, logreg2_10_cls_model = train_fit_time(model,\n",
    "                                                                               param_distributions,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "# Pickle results\n",
    "with open(os.path.join(model_fldr, 'logreg2_10_cls_scores_params_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(logreg2_10_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open(os.path.join(model_fldr, 'logreg2_10_cls_model_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(logreg2_10_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.6667773645058448,\n",
       " 'best_test_score': 0.6586985391766268,\n",
       " 'time_sec': 1360.105574,\n",
       " 'time_best_fit_sec': 183.314682,\n",
       " 'best_params': {'model__penalty': 'elasticnet',\n",
       "  'model__l1_ratio': 0.2,\n",
       "  'model__C': 464.15888336127773},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=464.15888336127773, class_weight=None,\n",
       "                                     dual=False, fit_intercept=True,\n",
       "                                     intercept_scaling=1, l1_ratio=0.2,\n",
       "                                     max_iter=100, multi_class='multinomial',\n",
       "                                     n_jobs=None, penalty='elasticnet',\n",
       "                                     random_state=3, solver='saga', tol=0.0001,\n",
       "                                     verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[1.74245414e-04, 7.62683216e-05, 7.16077728e-05, ...,\n",
       "         2.60861670e-02, 6.27428398e-07, 6.61212979e-05],\n",
       "        [4.65809021e-05, 3.09391539e-08, 6.34951224e-04, ...,\n",
       "         1.57900207e-01, 4.11196269e-04, 1.56824023e-04],\n",
       "        [9.47784802e-01, 3.45306001e-06, 1.48909901e-06, ...,\n",
       "         1.49947669e-02, 1.81480659e-02, 1.59405728e-07],\n",
       "        ...,\n",
       "        [3.62965950e-04, 2.86304511e-06, 5.49427052e-03, ...,\n",
       "         1.53859798e-02, 1.53858719e-05, 1.87143122e-06],\n",
       "        [1.57776281e-06, 3.30569379e-09, 4.98554617e-06, ...,\n",
       "         6.37477682e-03, 9.69950512e-08, 8.72515149e-09],\n",
       "        [2.38416240e-05, 9.26729742e-05, 3.16975375e-05, ...,\n",
       "         1.62873357e-03, 1.34036745e-07, 7.82307299e-07]]),\n",
       " 'best_y_hat': array(['music', 'footsteps', 'blender', ..., 'music', 'music', 'music'],\n",
       "       dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([240.04335117, 239.57614079, 239.94755263, 238.18488364,\n",
       "         109.41628156, 239.39096742, 238.93865423, 109.8402432 ,\n",
       "         108.89132333, 105.15176997]),\n",
       "  'std_fit_time': array([0.54948495, 0.97188067, 1.06819582, 2.84001357, 0.31562477,\n",
       "         1.02749957, 1.65212466, 1.24154333, 2.21688512, 1.88769469]),\n",
       "  'mean_score_time': array([0.04375477, 0.04375863, 0.04049401, 0.03977551, 0.03924317,\n",
       "         0.04101543, 0.03835406, 0.03902426, 0.03616037, 0.02414126]),\n",
       "  'std_score_time': array([0.00119053, 0.0028379 , 0.00128701, 0.00147018, 0.00163677,\n",
       "         0.00123716, 0.00034733, 0.00136405, 0.00634295, 0.00070163]),\n",
       "  'param_model__penalty': masked_array(data=['elasticnet', 'elasticnet', 'elasticnet', 'elasticnet',\n",
       "                     'elasticnet', 'elasticnet', 'elasticnet', 'elasticnet',\n",
       "                     'elasticnet', 'elasticnet'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__l1_ratio': masked_array(data=[0.2, 0.6000000000000001, 0.6000000000000001,\n",
       "                     0.7000000000000001, 0.0, 0.9, 0.30000000000000004, 0.0,\n",
       "                     0.0, 0.0],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__C': masked_array(data=[464.15888336127773, 59.94842503189409,\n",
       "                     464.15888336127773, 10000.0, 1291.5496650148827,\n",
       "                     59.94842503189409, 3593.813663804626, 10000.0,\n",
       "                     21.544346900318832, 7.742636826811269],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.2,\n",
       "    'model__C': 464.15888336127773},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.6000000000000001,\n",
       "    'model__C': 59.94842503189409},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.6000000000000001,\n",
       "    'model__C': 464.15888336127773},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.7000000000000001,\n",
       "    'model__C': 10000.0},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.0,\n",
       "    'model__C': 1291.5496650148827},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.9,\n",
       "    'model__C': 59.94842503189409},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.30000000000000004,\n",
       "    'model__C': 3593.813663804626},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.0,\n",
       "    'model__C': 10000.0},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.0,\n",
       "    'model__C': 21.544346900318832},\n",
       "   {'model__penalty': 'elasticnet',\n",
       "    'model__l1_ratio': 0.0,\n",
       "    'model__C': 7.742636826811269}],\n",
       "  'split0_test_score': array([0.67086928, 0.67086928, 0.67086928, 0.67086928, 0.67086928,\n",
       "         0.67086928, 0.67086928, 0.67086928, 0.67086928, 0.67086928]),\n",
       "  'split1_test_score': array([0.6749668, 0.6749668, 0.6749668, 0.6749668, 0.6749668, 0.6749668,\n",
       "         0.6749668, 0.6749668, 0.6749668, 0.6749668]),\n",
       "  'split2_test_score': array([0.66223846, 0.66223846, 0.66223846, 0.66223846, 0.66223846,\n",
       "         0.66223846, 0.66223846, 0.66223846, 0.66223846, 0.66223846]),\n",
       "  'split3_test_score': array([0.65149502, 0.65149502, 0.65149502, 0.65149502, 0.65149502,\n",
       "         0.65149502, 0.65149502, 0.65149502, 0.65149502, 0.65149502]),\n",
       "  'split4_test_score': array([0.6743104, 0.6743104, 0.6743104, 0.6743104, 0.6743104, 0.6743104,\n",
       "         0.6743104, 0.6743104, 0.6743104, 0.6743104]),\n",
       "  'mean_test_score': array([0.66677736, 0.66677736, 0.66677736, 0.66677736, 0.66677736,\n",
       "         0.66677736, 0.66677736, 0.66677736, 0.66677736, 0.66677736]),\n",
       "  'std_test_score': array([0.00888377, 0.00888377, 0.00888377, 0.00888377, 0.00888377,\n",
       "         0.00888377, 0.00888377, 0.00888377, 0.00888377, 0.00888377]),\n",
       "  'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load parameters and scores\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg2_10_cls_scores_params_rand.pkl'), 'rb')\n",
    "logreg2_10_cls_scores_params = pickle.load(pickling_out)\n",
    "logreg2_10_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept=True,\n",
       "                                                                 intercept_scaling=1,\n",
       "                                                                 l1_ratio=None,\n",
       "                                                                 max_iter=100,\n",
       "                                                                 multi_class='mul...\n",
       "                   param_distributions={'model__C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04]),\n",
       "                                        'model__l1_ratio': [0.0, 0.1, 0.2,\n",
       "                                                            0.30000000000000004,\n",
       "                                                            0.4, 0.5,\n",
       "                                                            0.6000000000000001,\n",
       "                                                            0.7000000000000001,\n",
       "                                                            0.8, 0.9],\n",
       "                                        'model__penalty': ['elasticnet']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best model\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg2_10_cls_model_rand.pkl'), 'rb')\n",
    "logreg2_10_cls_model = pickle.load(pickling_out)\n",
    "logreg2_10_cls_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and fit logistic regression with  RandomizedSearchCV: 3rd set of parameteres\n",
    "# from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = LogisticRegression(random_state=3, multi_class='multinomial')\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "penalty = ['l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "solver = ['sag', 'lbfgs', 'newton-cg']\n",
    "\n",
    "param_distributions = dict(\n",
    "        model__C = C, \n",
    "        model__penalty = penalty,\n",
    "        model__solver=solver\n",
    ")\n",
    "\n",
    "# Call parameter selection function\n",
    "logreg3_10_cls_scores_params, logreg3_10_cls_model = train_fit_time(model,\n",
    "                                                                               param_distributions,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "# Pickle results\n",
    "with open(os.path.join(model_fldr,'logreg3_10_cls_scores_params_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(logreg3_10_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open(os.path.join(model_fldr, 'logreg3_10_cls_model_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(logreg3_10_cls_model, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.6875664187035069,\n",
       " 'best_test_score': 0.6799468791500664,\n",
       " 'time_sec': 686.810264,\n",
       " 'time_best_fit_sec': 1.8927684,\n",
       " 'best_params': {'model__solver': 'lbfgs',\n",
       "  'model__penalty': 'l2',\n",
       "  'model__C': 7.742636826811269},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  LogisticRegression(C=7.742636826811269, class_weight=None,\n",
       "                                     dual=False, fit_intercept=True,\n",
       "                                     intercept_scaling=1, l1_ratio=None,\n",
       "                                     max_iter=100, multi_class='multinomial',\n",
       "                                     n_jobs=None, penalty='l2', random_state=3,\n",
       "                                     solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                     warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[3.57806073e-03, 2.25388809e-03, 4.80812102e-04, ...,\n",
       "         4.06820751e-02, 1.24415929e-04, 9.90912315e-04],\n",
       "        [1.55561046e-04, 1.58250961e-05, 5.72138800e-03, ...,\n",
       "         6.15624179e-01, 2.34227073e-03, 6.11502537e-03],\n",
       "        [9.33693019e-01, 7.49391642e-05, 9.55919783e-07, ...,\n",
       "         1.13183426e-02, 3.88151495e-02, 5.97181332e-05],\n",
       "        ...,\n",
       "        [3.02793092e-03, 7.60992817e-04, 8.29220199e-03, ...,\n",
       "         2.95361261e-02, 3.78893331e-04, 3.78360840e-04],\n",
       "        [7.17549495e-05, 3.51451020e-06, 3.91374355e-05, ...,\n",
       "         3.79269890e-03, 9.29772048e-06, 5.84816927e-06],\n",
       "        [4.74324133e-04, 2.60309886e-03, 4.09000345e-05, ...,\n",
       "         5.94152105e-03, 1.59744909e-05, 2.78087488e-04]]),\n",
       " 'best_y_hat': array(['music', 'speech', 'blender', ..., 'music', 'music', 'music'],\n",
       "       dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([589.5211534 , 120.89597054,   9.92424345,   9.93918366,\n",
       "         120.3567482 ,   9.42123442,   9.93431511, 101.92428255,\n",
       "           6.40768409,  71.66902232]),\n",
       "  'std_fit_time': array([54.07088429,  0.82922767,  0.14376991,  0.1818216 ,  0.48277048,\n",
       "          0.88929771,  0.20183322,  9.28465595,  0.11137137,  6.38037868]),\n",
       "  'mean_score_time': array([0.04540906, 0.06043673, 0.05380816, 0.05443773, 0.06025658,\n",
       "         0.05404811, 0.05632505, 0.04535079, 0.04841013, 0.0251718 ]),\n",
       "  'std_score_time': array([0.00937473, 0.00188828, 0.00069856, 0.00090596, 0.0053712 ,\n",
       "         0.005331  , 0.00370055, 0.0014496 , 0.00610234, 0.0018224 ]),\n",
       "  'param_model__solver': masked_array(data=['newton-cg', 'sag', 'lbfgs', 'lbfgs', 'sag', 'lbfgs',\n",
       "                     'lbfgs', 'sag', 'lbfgs', 'sag'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__penalty': masked_array(data=['l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                     'l2'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__C': masked_array(data=[7.742636826811269, 166.81005372000593,\n",
       "                     2.7825594022071245, 1.0, 3593.813663804626,\n",
       "                     7.742636826811269, 59.94842503189409,\n",
       "                     2.7825594022071245, 21.544346900318832,\n",
       "                     464.15888336127773],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__solver': 'newton-cg',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 7.742636826811269},\n",
       "   {'model__solver': 'sag',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 166.81005372000593},\n",
       "   {'model__solver': 'lbfgs',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 2.7825594022071245},\n",
       "   {'model__solver': 'lbfgs', 'model__penalty': 'l2', 'model__C': 1.0},\n",
       "   {'model__solver': 'sag',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 3593.813663804626},\n",
       "   {'model__solver': 'lbfgs',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 7.742636826811269},\n",
       "   {'model__solver': 'lbfgs',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 59.94842503189409},\n",
       "   {'model__solver': 'sag',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 2.7825594022071245},\n",
       "   {'model__solver': 'lbfgs',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 21.544346900318832},\n",
       "   {'model__solver': 'sag',\n",
       "    'model__penalty': 'l2',\n",
       "    'model__C': 464.15888336127773}],\n",
       "  'split0_test_score': array([0.64333112, 0.66290644, 0.69011281, 0.68347711, 0.66290644,\n",
       "         0.69143995, 0.68978102, 0.66290644, 0.69177173, 0.66290644]),\n",
       "  'split1_test_score': array([0.6497344 , 0.6689907 , 0.6938911 , 0.69787517, 0.6689907 ,\n",
       "         0.69588313, 0.69455511, 0.6689907 , 0.69555113, 0.6689907 ]),\n",
       "  'split2_test_score': array([0.62803055, 0.65725673, 0.67917635, 0.67718366, 0.65725673,\n",
       "         0.68714713, 0.67485885, 0.65725673, 0.67950847, 0.65725673]),\n",
       "  'split3_test_score': array([0.62325581, 0.64019934, 0.67973422, 0.67109635, 0.64019934,\n",
       "         0.6744186 , 0.67607973, 0.64019934, 0.67375415, 0.64019934]),\n",
       "  'split4_test_score': array([0.63376537, 0.66733134, 0.6889332 , 0.69125955, 0.66733134,\n",
       "         0.6889332 , 0.69092722, 0.66733134, 0.69059488, 0.66733134]),\n",
       "  'mean_test_score': array([0.63562699, 0.65933847, 0.68637088, 0.68417906, 0.65933847,\n",
       "         0.68756642, 0.68524176, 0.65933847, 0.68623804, 0.65933847]),\n",
       "  'std_test_score': array([0.00972246, 0.01039486, 0.00588099, 0.00957335, 0.01039486,\n",
       "         0.00719782, 0.00814117, 0.01039486, 0.00821516, 0.01039486]),\n",
       "  'rank_test_score': array([10,  6,  2,  5,  6,  1,  4,  6,  3,  6], dtype=int32)}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open(os.path.join(model_fldr, 'logreg3_10_cls_scores_params_rand.pkl'), 'rb')\n",
    "logreg3_10_cls_scores_params = pickle.load(unpicking_out)\n",
    "logreg3_10_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept=True,\n",
       "                                                                 intercept_scaling=1,\n",
       "                                                                 l1_ratio=None,\n",
       "                                                                 max_iter=100,\n",
       "                                                                 multi_class='mul...\n",
       "                   param_distributions={'model__C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04]),\n",
       "                                        'model__penalty': ['l2'],\n",
       "                                        'model__solver': ['sag', 'lbfgs',\n",
       "                                                          'newton-cg']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle best model\n",
    "unpicking_out = open(os.path.join(model_fldr, 'logreg3_10_cls_model_rand.pkl'), 'rb')\n",
    "logreg3_10_cls_model = pickle.load(unpicking_out)\n",
    "logreg3_10_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: logistic regression classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model scores\n",
    "\n",
    "model_fldr = '/Users/greenapple/project3/aws/models'\n",
    "\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg1_10_cls_scores_params_rand.pkl'), 'rb')\n",
    "logreg1_10_cls_scores_params_rand = pickle.load(pickling_out)\n",
    "pickling_out.close()\n",
    "\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg2_10_cls_scores_params_rand.pkl'), 'rb')\n",
    "logreg2_10_cls_scores_params_rand = pickle.load(pickling_out)\n",
    "pickling_out.close()\n",
    "\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg3_10_cls_scores_params_rand.pkl'), 'rb')\n",
    "logreg3_10_cls_scores_params_rand = pickle.load(pickling_out)\n",
    "pickling_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoadMake df with model scores\n",
    "logreg_table = pd.DataFrame()\n",
    "logreg_table['model'] = ['logreg1', 'logreg2', 'logreg3']\n",
    "logreg_table['f1_train'] = [\n",
    "    logreg1_10_cls_scores_params_rand['best_train_score'],\n",
    "    logreg2_10_cls_scores_params_rand['best_train_score'],\n",
    "    logreg3_10_cls_scores_params_rand['best_train_score']   \n",
    "]\n",
    "\n",
    "logreg_table['f1_test'] = [\n",
    "    logreg1_10_cls_scores_params_rand['best_test_score'],\n",
    "    logreg2_10_cls_scores_params_rand['best_test_score'],\n",
    "    logreg3_10_cls_scores_params_rand['best_test_score']   \n",
    "]\n",
    "\n",
    "logreg_table['train_time'] = [\n",
    "    logreg1_10_cls_scores_params_rand['time_best_fit_sec'],\n",
    "    logreg2_10_cls_scores_params_rand['time_best_fit_sec'],\n",
    "    logreg3_10_cls_scores_params_rand['time_best_fit_sec']   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T21:32:53.841787Z",
     "start_time": "2019-10-25T21:32:53.768858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>logreg1</td>\n",
       "      <td>0.685707</td>\n",
       "      <td>0.678353</td>\n",
       "      <td>205.980575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>logreg2</td>\n",
       "      <td>0.666777</td>\n",
       "      <td>0.658699</td>\n",
       "      <td>183.314682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>logreg3</td>\n",
       "      <td>0.687566</td>\n",
       "      <td>0.679947</td>\n",
       "      <td>1.892768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  f1_train   f1_test  train_time\n",
       "0  logreg1  0.685707  0.678353  205.980575\n",
       "1  logreg2  0.666777  0.658699  183.314682\n",
       "2  logreg3  0.687566  0.679947    1.892768"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best logreg model is logreg3_10_cls_scores_params. Will be using this model for ensembling models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T04:08:58.711750Z",
     "start_time": "2019-10-19T04:08:58.704570Z"
    }
   },
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T22:44:05.517998Z",
     "start_time": "2019-10-21T22:43:22.018705Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'KNN_10_cls_scores_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-418f4f3b62e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Pickle results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fldr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'KNN_10_cls_scores_params_rand.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKNN_10_cls_scores_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Pickle model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KNN_10_cls_scores_params' is not defined"
     ]
    }
   ],
   "source": [
    "# Train and fit KNN with  RandomizedSearchCV\n",
    "# from src.models import model_os.path.join(model_fldr,sel_rand_search)\n",
    "\n",
    "# Function arguments:\n",
    "model = KNeighborsClassifier()\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "k_range = list(range(1, 10, 1))\n",
    "\n",
    "param_grid = dict(model__n_neighbors=k_range)\n",
    "\n",
    "# Call parameter selection function\n",
    "KNN_30_cls_scores_params, KNN_30_cls_model = train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open(os.path.join(model_fldr,'KNN_10_cls_scores_params_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(KNN_10_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open(os.path.join(model_fldr,'KNN_10_cls_model_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(KNN_10_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle results\n",
    "with open(os.path.join(model_fldr,'KNN_10_cls_scores_params_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(KNN_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open(os.path.join(model_fldr,'KNN_10_cls_model_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(KNN_30_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.5996280552603613,\n",
       " 'best_test_score': 0.6,\n",
       " 'time_sec': 490.554191,\n",
       " 'time_best_fit_sec': 0.2989806,\n",
       " 'best_params': {'model__n_neighbors': 1},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                       metric='minkowski', metric_params=None,\n",
       "                                       n_jobs=None, n_neighbors=1, p=2,\n",
       "                                       weights='uniform'))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'best_y_hat': array(['music', 'footsteps', 'speech', ..., 'music', 'music', 'music'],\n",
       "       dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([0.85925503, 0.83767571, 0.77536955, 0.77851796, 0.82101474,\n",
       "         0.82743635, 0.76970019, 0.80217857, 0.78206048]),\n",
       "  'std_fit_time': array([0.00833606, 0.04071316, 0.0204188 , 0.01312812, 0.04981858,\n",
       "         0.06776769, 0.00603869, 0.01082447, 0.01149333]),\n",
       "  'mean_score_time': array([84.03226042, 84.72691264, 83.66446981, 83.7509757 , 83.88269715,\n",
       "         83.40984664, 84.52309513, 85.03665504, 64.40915961]),\n",
       "  'std_score_time': array([0.78047432, 1.08653332, 0.82756627, 0.71311194, 0.84502205,\n",
       "         1.04999625, 0.60448816, 0.67957471, 2.42695111]),\n",
       "  'param_model__n_neighbors': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__n_neighbors': 1},\n",
       "   {'model__n_neighbors': 2},\n",
       "   {'model__n_neighbors': 3},\n",
       "   {'model__n_neighbors': 4},\n",
       "   {'model__n_neighbors': 5},\n",
       "   {'model__n_neighbors': 6},\n",
       "   {'model__n_neighbors': 7},\n",
       "   {'model__n_neighbors': 8},\n",
       "   {'model__n_neighbors': 9}],\n",
       "  'split0_test_score': array([0.60484406, 0.56303915, 0.57631055, 0.56668879, 0.56237558,\n",
       "         0.54844061, 0.53815528, 0.53351029, 0.52090246]),\n",
       "  'split1_test_score': array([0.60126162, 0.56142098, 0.5876494 , 0.57138114, 0.56474104,\n",
       "         0.55112882, 0.54747676, 0.5375166 , 0.52755644]),\n",
       "  'split2_test_score': array([0.60146131, 0.55131186, 0.56459648, 0.5586184 , 0.55363667,\n",
       "         0.53968781, 0.528728  , 0.52540684, 0.51444703]),\n",
       "  'split3_test_score': array([0.58936877, 0.55282392, 0.57508306, 0.56611296, 0.5551495 ,\n",
       "         0.5461794 , 0.5358804 , 0.52890365, 0.5179402 ]),\n",
       "  'split4_test_score': array([0.60119641, 0.55068129, 0.57128614, 0.55500166, 0.55234297,\n",
       "         0.5407112 , 0.5333998 , 0.52542373, 0.51744766]),\n",
       "  'mean_test_score': array([0.59962806, 0.55585813, 0.57498672, 0.5635627 , 0.55765143,\n",
       "         0.54523114, 0.53672954, 0.53015409, 0.51965994]),\n",
       "  'std_test_score': array([0.00530906, 0.00527672, 0.00753371, 0.00591793, 0.00496282,\n",
       "         0.00440777, 0.00621914, 0.00473188, 0.00444828]),\n",
       "  'rank_test_score': array([1, 5, 2, 3, 4, 6, 7, 8, 9], dtype=int32)}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open(os.path.join(model_fldr,'KNN_10_cls_scores_params_rand.pkl'), 'rb')\n",
    "KNN_10_cls_scores_params = pickle.load(unpicking_out)\n",
    "KNN_10_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                                   leaf_size=30,\n",
       "                                                                   metric='minkowski',\n",
       "                                                                   metric_params=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   n_neighbors=5,\n",
       "                                                                   p=2,\n",
       "                                                                   weights='uniform'))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'model__n_neighbors': [1, 2, 3, 4, 5, 6,\n",
       "                                                               7, 8, 9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open(os.path.join(model_fldr,'KNN_10_cls_model_rand.pkl'), 'rb')\n",
    "KNN_10_cls_model = pickle.load(unpicking_out)\n",
    "KNN_10_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes MultiNomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T22:46:31.708756Z",
     "start_time": "2019-10-21T22:46:31.269131Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:266: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train and fit naive Bayes MultiNomial with RandomizedSearchCV\n",
    "# from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = MultinomialNB()\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "alphas = [1, 10, 100]\n",
    "# Selects the min alpha. Keep alpha = 1 to make sure the model can take data it has not seen before \n",
    "# from the test set.\n",
    "\n",
    "param_grid = dict(model__alpha=alphas)\n",
    "\n",
    "# Call parameter selection function\n",
    "NBmultinomial_10_cls_scores_params, NBmultinomial_10_cls_model = train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open(os.path.join(model_fldr,'NBmultinomial_10_cls_scores_params_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(NBmultinomial_10_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open(os.path.join(model_fldr, 'NBmultinomial_10_cls_model_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(NBmultinomial_10_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.6592720510095643,\n",
       " 'best_test_score': 0.6398406374501993,\n",
       " 'time_sec': 2.933915,\n",
       " 'time_best_fit_sec': 0.0907902,\n",
       " 'best_params': {'model__alpha': 1},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  MultinomialNB(alpha=1, class_prior=None, fit_prior=True))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "         1.66292612e-178, 0.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "        ...,\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "         8.52905765e-092, 0.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "         1.60431252e-149, 0.00000000e+000, 0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "         7.94075424e-222, 0.00000000e+000, 0.00000000e+000]]),\n",
       " 'best_y_hat': array(['music', 'footsteps', 'blender', ..., 'music', 'music', 'music'],\n",
       "       dtype='<U14'),\n",
       " 'all_scores': {'mean_fit_time': array([0.28154855, 0.28932047, 0.25218844]),\n",
       "  'std_fit_time': array([0.01041398, 0.02152866, 0.02058036]),\n",
       "  'mean_score_time': array([0.04143467, 0.03934722, 0.02896605]),\n",
       "  'std_score_time': array([0.00446362, 0.00233754, 0.01007   ]),\n",
       "  'param_model__alpha': masked_array(data=[1, 10, 100],\n",
       "               mask=[False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__alpha': 1}, {'model__alpha': 10}, {'model__alpha': 100}],\n",
       "  'split0_test_score': array([0.6592568 , 0.6592568 , 0.65892502]),\n",
       "  'split1_test_score': array([0.66666667, 0.66666667, 0.66633466]),\n",
       "  'split2_test_score': array([0.65825307, 0.65825307, 0.65858519]),\n",
       "  'split3_test_score': array([0.64684385, 0.64684385, 0.64684385]),\n",
       "  'split4_test_score': array([0.66533732, 0.66533732, 0.66533732]),\n",
       "  'mean_test_score': array([0.65927205, 0.65927205, 0.65920563]),\n",
       "  'std_test_score': array([0.00702698, 0.00702698, 0.00695159]),\n",
       "  'rank_test_score': array([1, 1, 3], dtype=int32)}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open(os.path.join(model_fldr, 'NBmultinomial_10_cls_scores_params_rand.pkl'), 'rb')\n",
    "NBmultinomial_10_cls_scores_params = pickle.load(unpicking_out)\n",
    "NBmultinomial_10_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              MultinomialNB(alpha=1.0,\n",
       "                                                            class_prior=None,\n",
       "                                                            fit_prior=True))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'model__alpha': [1, 10, 100]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle best model\n",
    "unpicking_out = open(os.path.join(model_fldr, 'NBmultinomial_10_cls_model_rand.pkl'), 'rb')\n",
    "NBmultinomial_10_cls_model = pickle.load(unpicking_out)\n",
    "NBmultinomial_10_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T23:20:52.968294Z",
     "start_time": "2019-10-21T22:48:22.725052Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train and fit SVC with RandomizedSearchCV\n",
    "# from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = SVC(probability=True)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "gamma = [0.01, 0.1, 1, 10]\n",
    "degree = [2, 3, 4]\n",
    "\n",
    "param_grid = dict(model__C=C,\n",
    "                 model__kernel=kernel,\n",
    "                 model__gamma=gamma,\n",
    "                 model__degree=degree\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "SVC_10_cls_scores_params, SVC_10_cls_model =train_fit_time(model,\n",
    "                                                                               param_grid,\n",
    "                                                                               transformer,\n",
    "                                                                               X_train,\n",
    "                                                                               X_test,\n",
    "                                                                               y_train,\n",
    "                                                                               y_test,\n",
    "                                                                               CV)\n",
    "\n",
    "# Pickle results\n",
    "with open(os.path.join(model_fldr, 'SVC_10_cls_scores_params_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(SVC_10_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open(os.path.join(model_fldr,'SVC_10_cls_model_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(SVC_10_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open(os.path.join(model_fldr,'SVC_10_cls_scores_params_rand.pkl'), 'rb')\n",
    "SVC_10_cls_scores_params = pickle.load(unpicking_out)\n",
    "SVC_10_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle model\n",
    "unpicking_out = open(os.path.join(model_fldr,'SVC_10_cls_model_rand.pkl'), 'rb')\n",
    "SVC_10_cls_model = pickle.load(unpicking_out)\n",
    "SVC_10_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T06:52:24.564264Z",
     "start_time": "2019-10-22T06:09:22.157127Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_fldr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-71271340ffaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Pickle results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fldr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RF_10_cls_scores_params_rand.pkl.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRF_10_cls_scores_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_fldr' is not defined"
     ]
    }
   ],
   "source": [
    "# Train and fit Random Forest\n",
    "# from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = RandomForestClassifier(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "n_estimators = [10, 50, 100, 300, 500]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [5, 10, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10, 50]\n",
    "max_features = [5, 10, 25, 50, 100]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "                \n",
    "param_grid = dict(model__n_estimators=n_estimators,\n",
    "                  model__criterion=criterion,\n",
    "                  model__max_depth=max_depth,\n",
    "                  model__min_samples_split=min_samples_split,\n",
    "                  model__max_features=max_features,\n",
    "                  model__bootstrap=bootstrap\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "RF_10_cls_scores_params, RF_10_cls_model = train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open(os.path.join(model_fldr,'RF_10_cls_scores_params_rand.pkl.pkl'), 'wb') as f:\n",
    "    pickle.dump(RF_10_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open(os.path.join(model_fldr, 'RF_10_cls_model_rand.pkl.pkl'), 'wb') as f:\n",
    "    pickle.dump(RF_10_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle results\n",
    "with open(os.path.join(model_fldr,'RF_10_cls_scores_params_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(RF_10_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open(os.path.join(model_fldr, 'RF_10_cls_model_rand.pkl'), 'wb') as f:\n",
    "    pickle.dump(RF_10_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.6880313496280552,\n",
       " 'best_test_score': 0.6873837981407702,\n",
       " 'time_sec': 590.899273,\n",
       " 'time_best_fit_sec': 33.69221,\n",
       " 'best_params': {'model__n_estimators': 300,\n",
       "  'model__min_samples_split': 10,\n",
       "  'model__max_features': 10,\n",
       "  'model__max_depth': 50,\n",
       "  'model__criterion': 'gini',\n",
       "  'model__bootstrap': True},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                         criterion='gini', max_depth=50,\n",
       "                                         max_features=10, max_leaf_nodes=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1,\n",
       "                                         min_samples_split=10,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators=300, n_jobs=None,\n",
       "                                         oob_score=False, random_state=3,\n",
       "                                         verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[0.07606002, 0.04995442, 0.06602142, ..., 0.2626655 , 0.04374071,\n",
       "         0.02489911],\n",
       "        [0.06215248, 0.01710847, 0.09813577, ..., 0.18529467, 0.06654492,\n",
       "         0.05287787],\n",
       "        [0.37431091, 0.01858509, 0.0521877 , ..., 0.14362317, 0.17388186,\n",
       "         0.02314633],\n",
       "        ...,\n",
       "        [0.02977713, 0.04281036, 0.03541847, ..., 0.2127897 , 0.02257875,\n",
       "         0.00862988],\n",
       "        [0.02383946, 0.02446316, 0.01355871, ..., 0.12210593, 0.00928571,\n",
       "         0.00462458],\n",
       "        [0.01950775, 0.07730866, 0.02032258, ..., 0.11696367, 0.0151452 ,\n",
       "         0.00106838]]),\n",
       " 'best_y_hat': array(['music', 'footsteps', 'blender', ..., 'music', 'music', 'music'],\n",
       "       dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([ 23.13747172,   8.46518259,  38.08093829,  28.0190486 ,\n",
       "          22.52813926,  11.55416918,  25.78282356,   5.85636234,\n",
       "         340.45567136, 227.62972836]),\n",
       "  'std_fit_time': array([1.36467249e-01, 1.82794481e-01, 1.05918395e-01, 8.47819285e-02,\n",
       "         1.77243675e-01, 4.51767501e-02, 1.22148107e-01, 1.82980319e-02,\n",
       "         2.33607476e+00, 2.76101851e+01]),\n",
       "  'mean_score_time': array([0.12861166, 0.04646835, 0.38936591, 0.18017178, 0.04447212,\n",
       "         0.04824333, 0.12368603, 0.0643548 , 0.28803105, 0.31606154]),\n",
       "  'std_score_time': array([4.45406110e-03, 4.53336311e-03, 7.37936297e-03, 1.34103673e-02,\n",
       "         3.03492134e-04, 7.43823866e-04, 2.46018526e-03, 6.39363063e-05,\n",
       "         4.47928245e-02, 5.48122173e-02]),\n",
       "  'param_model__n_estimators': masked_array(data=[100, 10, 300, 100, 10, 10, 100, 50, 300, 300],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__min_samples_split': masked_array(data=[50, 10, 10, 5, 50, 5, 50, 2, 50, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_features': masked_array(data=[10, 100, 10, 5, 100, 25, 10, 10, 50, 25],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_depth': masked_array(data=[10, 10, 50, 100, 50, None, 50, 5, 50, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__criterion': masked_array(data=['entropy', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__bootstrap': masked_array(data=[True, True, True, False, True, False, True, False,\n",
       "                     True, False],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__n_estimators': 100,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 10,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 100,\n",
       "    'model__max_depth': 10,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 50,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 100,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': 100,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False},\n",
       "   {'model__n_estimators': 10,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 100,\n",
       "    'model__max_depth': 50,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__max_depth': None,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False},\n",
       "   {'model__n_estimators': 100,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 50,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 5,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 50,\n",
       "    'model__max_depth': 50,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__max_depth': 10,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False}],\n",
       "  'split0_test_score': array([0.64963504, 0.66489715, 0.69376244, 0.68779031, 0.67086928,\n",
       "         0.65428003, 0.65693431, 0.54313205, 0.68546782, 0.68414068]),\n",
       "  'split1_test_score': array([0.65537849, 0.66301461, 0.69488712, 0.68492696, 0.66102258,\n",
       "         0.65106242, 0.6626826 , 0.54548473, 0.68691899, 0.68891102]),\n",
       "  'split2_test_score': array([0.63865825, 0.6459648 , 0.68581866, 0.67054135, 0.65360345,\n",
       "         0.64197941, 0.65327134, 0.53636666, 0.67651943, 0.66921289]),\n",
       "  'split3_test_score': array([0.63122924, 0.64186047, 0.67508306, 0.65481728, 0.64019934,\n",
       "         0.63122924, 0.64252492, 0.54086379, 0.66910299, 0.66112957]),\n",
       "  'split4_test_score': array([0.64672649, 0.64440013, 0.69059488, 0.67730143, 0.65004985,\n",
       "         0.6477235 , 0.64905284, 0.54004653, 0.68062479, 0.68228647]),\n",
       "  'mean_test_score': array([0.64432784, 0.65203241, 0.68803135, 0.6750797 , 0.65515409,\n",
       "         0.6452577 , 0.65289586, 0.5411796 , 0.67972901, 0.67713868]),\n",
       "  'std_test_score': array([0.0084822 , 0.00984628, 0.00719644, 0.01178672, 0.01033092,\n",
       "         0.00810831, 0.00684898, 0.00306268, 0.00645978, 0.01032649]),\n",
       "  'rank_test_score': array([ 9,  7,  1,  4,  5,  8,  6, 10,  2,  3], dtype=int32)}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_10_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.6880313496280552,\n",
       " 'best_test_score': 0.6873837981407702,\n",
       " 'time_sec': 590.899273,\n",
       " 'time_best_fit_sec': 33.69221,\n",
       " 'best_params': {'model__n_estimators': 300,\n",
       "  'model__min_samples_split': 10,\n",
       "  'model__max_features': 10,\n",
       "  'model__max_depth': 50,\n",
       "  'model__criterion': 'gini',\n",
       "  'model__bootstrap': True},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                         criterion='gini', max_depth=50,\n",
       "                                         max_features=10, max_leaf_nodes=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1,\n",
       "                                         min_samples_split=10,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators=300, n_jobs=None,\n",
       "                                         oob_score=False, random_state=3,\n",
       "                                         verbose=0, warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[0.07606002, 0.04995442, 0.06602142, ..., 0.2626655 , 0.04374071,\n",
       "         0.02489911],\n",
       "        [0.06215248, 0.01710847, 0.09813577, ..., 0.18529467, 0.06654492,\n",
       "         0.05287787],\n",
       "        [0.37431091, 0.01858509, 0.0521877 , ..., 0.14362317, 0.17388186,\n",
       "         0.02314633],\n",
       "        ...,\n",
       "        [0.02977713, 0.04281036, 0.03541847, ..., 0.2127897 , 0.02257875,\n",
       "         0.00862988],\n",
       "        [0.02383946, 0.02446316, 0.01355871, ..., 0.12210593, 0.00928571,\n",
       "         0.00462458],\n",
       "        [0.01950775, 0.07730866, 0.02032258, ..., 0.11696367, 0.0151452 ,\n",
       "         0.00106838]]),\n",
       " 'best_y_hat': array(['music', 'footsteps', 'blender', ..., 'music', 'music', 'music'],\n",
       "       dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([ 23.13747172,   8.46518259,  38.08093829,  28.0190486 ,\n",
       "          22.52813926,  11.55416918,  25.78282356,   5.85636234,\n",
       "         340.45567136, 227.62972836]),\n",
       "  'std_fit_time': array([1.36467249e-01, 1.82794481e-01, 1.05918395e-01, 8.47819285e-02,\n",
       "         1.77243675e-01, 4.51767501e-02, 1.22148107e-01, 1.82980319e-02,\n",
       "         2.33607476e+00, 2.76101851e+01]),\n",
       "  'mean_score_time': array([0.12861166, 0.04646835, 0.38936591, 0.18017178, 0.04447212,\n",
       "         0.04824333, 0.12368603, 0.0643548 , 0.28803105, 0.31606154]),\n",
       "  'std_score_time': array([4.45406110e-03, 4.53336311e-03, 7.37936297e-03, 1.34103673e-02,\n",
       "         3.03492134e-04, 7.43823866e-04, 2.46018526e-03, 6.39363063e-05,\n",
       "         4.47928245e-02, 5.48122173e-02]),\n",
       "  'param_model__n_estimators': masked_array(data=[100, 10, 300, 100, 10, 10, 100, 50, 300, 300],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__min_samples_split': masked_array(data=[50, 10, 10, 5, 50, 5, 50, 2, 50, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_features': masked_array(data=[10, 100, 10, 5, 100, 25, 10, 10, 50, 25],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_depth': masked_array(data=[10, 10, 50, 100, 50, None, 50, 5, 50, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__criterion': masked_array(data=['entropy', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                     'entropy', 'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__bootstrap': masked_array(data=[True, True, True, False, True, False, True, False,\n",
       "                     True, False],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__n_estimators': 100,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 10,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 10,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 100,\n",
       "    'model__max_depth': 10,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 50,\n",
       "    'model__criterion': 'gini',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 100,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': 100,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False},\n",
       "   {'model__n_estimators': 10,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 100,\n",
       "    'model__max_depth': 50,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 10,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__max_depth': None,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False},\n",
       "   {'model__n_estimators': 100,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 50,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 5,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 50,\n",
       "    'model__max_depth': 50,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': True},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__max_depth': 10,\n",
       "    'model__criterion': 'entropy',\n",
       "    'model__bootstrap': False}],\n",
       "  'split0_test_score': array([0.64963504, 0.66489715, 0.69376244, 0.68779031, 0.67086928,\n",
       "         0.65428003, 0.65693431, 0.54313205, 0.68546782, 0.68414068]),\n",
       "  'split1_test_score': array([0.65537849, 0.66301461, 0.69488712, 0.68492696, 0.66102258,\n",
       "         0.65106242, 0.6626826 , 0.54548473, 0.68691899, 0.68891102]),\n",
       "  'split2_test_score': array([0.63865825, 0.6459648 , 0.68581866, 0.67054135, 0.65360345,\n",
       "         0.64197941, 0.65327134, 0.53636666, 0.67651943, 0.66921289]),\n",
       "  'split3_test_score': array([0.63122924, 0.64186047, 0.67508306, 0.65481728, 0.64019934,\n",
       "         0.63122924, 0.64252492, 0.54086379, 0.66910299, 0.66112957]),\n",
       "  'split4_test_score': array([0.64672649, 0.64440013, 0.69059488, 0.67730143, 0.65004985,\n",
       "         0.6477235 , 0.64905284, 0.54004653, 0.68062479, 0.68228647]),\n",
       "  'mean_test_score': array([0.64432784, 0.65203241, 0.68803135, 0.6750797 , 0.65515409,\n",
       "         0.6452577 , 0.65289586, 0.5411796 , 0.67972901, 0.67713868]),\n",
       "  'std_test_score': array([0.0084822 , 0.00984628, 0.00719644, 0.01178672, 0.01033092,\n",
       "         0.00810831, 0.00684898, 0.00306268, 0.00645978, 0.01032649]),\n",
       "  'rank_test_score': array([ 9,  7,  1,  4,  5,  8,  6, 10,  2,  3], dtype=int32)}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open(os.path.join(model_fldr, 'RF_10_cls_scores_params_rand.pkl'), 'rb')\n",
    "RF_10_cls_scores_params = pickle.load(unpicking_out)\n",
    "RF_10_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              RandomForestClassifier(bootstrap=True,\n",
       "                                                                     class_weight=None,\n",
       "                                                                     criterion='gini',\n",
       "                                                                     max_depth=None,\n",
       "                                                                     max_features='auto',\n",
       "                                                                     max_leaf_nodes=None,\n",
       "                                                                     min_impu...\n",
       "                   param_distributions={'model__bootstrap': [True, False],\n",
       "                                        'model__criterion': ['gini', 'entropy'],\n",
       "                                        'model__max_depth': [5, 10, 50, 100,\n",
       "                                                             None],\n",
       "                                        'model__max_features': [5, 10, 25, 50,\n",
       "                                                                100],\n",
       "                                        'model__min_samples_split': [2, 5, 10,\n",
       "                                                                     50],\n",
       "                                        'model__n_estimators': [10, 50, 100,\n",
       "                                                                300, 500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle model\n",
    "unpicking_out = open(os.path.join(model_fldr,'RF_10_cls_model_rand.pkl'), 'rb')\n",
    "RF_10_cls_model = pickle.load(unpicking_out)\n",
    "RF_10_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T07:00:45.462798Z",
     "start_time": "2019-10-22T06:52:24.566680Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "# Train and fit Gradient Boosting\n",
    "# from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = GradientBoostingClassifier(random_state=3)\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "n_estimators = [50, 100, 300, 500]\n",
    "max_depth = [5, 10, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10, 20, 50]\n",
    "max_features = [5, 10, 25, 50, 100]\n",
    "\n",
    "\n",
    "param_grid = dict(model__n_estimators=n_estimators,\n",
    "                  model__max_depth=max_depth,\n",
    "                  model__min_samples_split=min_samples_split,\n",
    "                  model__max_features=max_features,\n",
    "                 )\n",
    "\n",
    "# Call parameter selection function\n",
    "GBM_10_cls_scores_params, GBM_10_cls_model = train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "# Pickle results\n",
    "with open(os.path.join(model_fldr,'GBM_10_cls_scores_params_rand.pkl.pkl.pkl'), 'wb') as f:\n",
    "    pickle.dump(GBM_10_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open(os.path.join(model_fldr, 'GBM_10_cls_model_rand.pkl.pkl.pkl'), 'wb') as f:\n",
    "    pickle.dump(GBM_10_cls_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_train_score': 0.7307385759829969,\n",
       " 'best_test_score': 0.7304116865869854,\n",
       " 'time_sec': 2570.612416,\n",
       " 'time_best_fit_sec': 129.15343,\n",
       " 'best_params': {'model__n_estimators': 300,\n",
       "  'model__min_samples_split': 10,\n",
       "  'model__max_features': 10,\n",
       "  'model__max_depth': 5},\n",
       " 'best_estimator': Pipeline(memory=None,\n",
       "          steps=[('transformer',\n",
       "                  RandomOverSampler(random_state=3, ratio=None,\n",
       "                                    return_indices=False,\n",
       "                                    sampling_strategy='minority')),\n",
       "                 ('model',\n",
       "                  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                                             learning_rate=0.1, loss='deviance',\n",
       "                                             max_depth=5, max_features=10,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=10,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=300,\n",
       "                                             n_iter_no_change=None,\n",
       "                                             presort='auto', random_state=3,\n",
       "                                             subsample=1.0, tol=0.0001,\n",
       "                                             validation_fraction=0.1, verbose=0,\n",
       "                                             warm_start=False))],\n",
       "          verbose=False),\n",
       " 'best_test_proba': array([[8.83398983e-03, 8.14482159e-04, 3.04259269e-03, ...,\n",
       "         1.08904615e-01, 8.16583924e-03, 5.76386896e-05],\n",
       "        [1.64368789e-02, 1.74072710e-04, 9.44208840e-03, ...,\n",
       "         3.87564741e-01, 4.07005976e-03, 2.67573014e-03],\n",
       "        [9.54500148e-01, 6.29319104e-05, 9.23929697e-04, ...,\n",
       "         2.43429830e-02, 6.79596357e-03, 5.20387016e-06],\n",
       "        ...,\n",
       "        [3.93711690e-03, 4.73821161e-04, 1.15642150e-02, ...,\n",
       "         1.88739492e-01, 3.44072284e-03, 4.42271588e-05],\n",
       "        [9.73339259e-05, 8.26373590e-06, 1.96327681e-04, ...,\n",
       "         8.72832170e-03, 1.51695763e-04, 2.26639726e-06],\n",
       "        [1.82653233e-04, 4.38875851e-05, 4.24154175e-05, ...,\n",
       "         4.62205752e-03, 4.44211992e-05, 1.39535419e-06]]),\n",
       " 'best_y_hat': array(['music', 'footsteps', 'blender', ..., 'music', 'music', 'music'],\n",
       "       dtype=object),\n",
       " 'all_scores': {'mean_fit_time': array([242.42823281,  69.00670528, 655.80245829, 565.44469938,\n",
       "         610.66617889, 760.94742575, 508.63346925, 228.00395508,\n",
       "          20.43029051, 173.87185869]),\n",
       "  'std_fit_time': array([ 1.24931369,  0.68053346, 22.1282212 , 14.65909484, 15.57215948,\n",
       "         17.65409621, 15.72567775,  6.52276785,  0.2196056 ,  7.07693291]),\n",
       "  'mean_score_time': array([0.17633815, 0.17993398, 1.25045586, 1.27515373, 1.26570168,\n",
       "         1.00808945, 0.89856949, 0.38284097, 0.17675343, 0.51073122]),\n",
       "  'std_score_time': array([0.00800723, 0.00506431, 0.12493735, 0.03346348, 0.0919058 ,\n",
       "         0.04577813, 0.16984149, 0.02143728, 0.01650524, 0.16825554]),\n",
       "  'param_model__n_estimators': masked_array(data=[50, 50, 500, 500, 500, 500, 300, 50, 50, 300],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__min_samples_split': masked_array(data=[5, 5, 50, 10, 5, 10, 50, 2, 20, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_features': masked_array(data=[100, 25, 10, 5, 5, 25, 10, 5, 5, 10],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_model__max_depth': masked_array(data=[5, 5, 50, None, 100, 10, 100, 50, 5, 5],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__max_features': 100,\n",
       "    'model__max_depth': 5},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__max_features': 25,\n",
       "    'model__max_depth': 5},\n",
       "   {'model__n_estimators': 500,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 50},\n",
       "   {'model__n_estimators': 500,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': None},\n",
       "   {'model__n_estimators': 500,\n",
       "    'model__min_samples_split': 5,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': 100},\n",
       "   {'model__n_estimators': 500,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 25,\n",
       "    'model__max_depth': 10},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 50,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 100},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 2,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': 50},\n",
       "   {'model__n_estimators': 50,\n",
       "    'model__min_samples_split': 20,\n",
       "    'model__max_features': 5,\n",
       "    'model__max_depth': 5},\n",
       "   {'model__n_estimators': 300,\n",
       "    'model__min_samples_split': 10,\n",
       "    'model__max_features': 10,\n",
       "    'model__max_depth': 5}],\n",
       "  'split0_test_score': array([0.71566025, 0.7123424 , 0.72992701, 0.71532847, 0.71035169,\n",
       "         0.72760451, 0.72893165, 0.66655607, 0.70305242, 0.73855342]),\n",
       "  'split1_test_score': array([0.72675963, 0.71215139, 0.73173971, 0.70982736, 0.70185923,\n",
       "         0.72709163, 0.73007968, 0.6689907 , 0.6938911 , 0.73373174]),\n",
       "  'split2_test_score': array([0.71105945, 0.70541348, 0.72102292, 0.70109598, 0.69545002,\n",
       "         0.71936234, 0.72201926, 0.65592826, 0.68150116, 0.72899369]),\n",
       "  'split3_test_score': array([0.70099668, 0.69634551, 0.70730897, 0.69368771, 0.68438538,\n",
       "         0.71428571, 0.70863787, 0.63355482, 0.67840532, 0.71594684]),\n",
       "  'split4_test_score': array([0.72283151, 0.71684945, 0.7337986 , 0.71485543, 0.71385842,\n",
       "         0.72648721, 0.73147225, 0.6596876 , 0.69724161, 0.73645729]),\n",
       "  'mean_test_score': array([0.71546227, 0.70862115, 0.72476089, 0.70696068, 0.70118225,\n",
       "         0.72296759, 0.72422954, 0.6569474 , 0.69082094, 0.73073858]),\n",
       "  'std_test_score': array([0.00906116, 0.00714005, 0.00975162, 0.00837951, 0.01058359,\n",
       "         0.00527738, 0.00844595, 0.01259388, 0.00939479, 0.00805633]),\n",
       "  'rank_test_score': array([ 5,  6,  2,  7,  8,  4,  3, 10,  9,  1], dtype=int32)}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle results\n",
    "unpicking_out = open(os.path.join(model_fldr,'GBM_10_cls_scores_params_rand.pkl.pkl.pkl'), 'rb')\n",
    "GBM_10_cls_scores_params = pickle.load(unpicking_out)\n",
    "GBM_10_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('transformer',\n",
       "                                              RandomOverSampler(random_state=3,\n",
       "                                                                ratio=None,\n",
       "                                                                return_indices=False,\n",
       "                                                                sampling_strategy='minority')),\n",
       "                                             ('model',\n",
       "                                              GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                                         init=None,\n",
       "                                                                         learning_rate=0.1,\n",
       "                                                                         loss='deviance',\n",
       "                                                                         max_depth=3,\n",
       "                                                                         max_features=None,\n",
       "                                                                         max_leaf_n...\n",
       "                                                                         warm_start=False))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'model__max_depth': [5, 10, 50, 100,\n",
       "                                                             None],\n",
       "                                        'model__max_features': [5, 10, 25, 50,\n",
       "                                                                100],\n",
       "                                        'model__min_samples_split': [2, 5, 10,\n",
       "                                                                     20, 50],\n",
       "                                        'model__n_estimators': [50, 100, 300,\n",
       "                                                                500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle model\n",
    "unpicking_out = open(os.path.join(model_fldr,'GBM_10_cls_model_rand.pkl.pkl.pkl'), 'rb')\n",
    "GBM_10_cls_model = pickle.load(unpicking_out)\n",
    "GBM_10_cls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:18.304982Z",
     "start_time": "2019-10-22T00:07:18.048965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train and fit Dummy classifier\n",
    "from src.models import model_sel_rand_search\n",
    "\n",
    "# Function arguments:\n",
    "model = DummyClassifier(random_state=3, strategy='stratified')\n",
    "transformer = RandomOverSampler(random_state=3, sampling_strategy='minority')\n",
    "CV = 5\n",
    "\n",
    "# Function arguments: classifier params\n",
    "\n",
    "param_grid = dict()\n",
    "\n",
    "# Call parameter selection function\n",
    "Dummy_30_cls_scores_params, Dummy_30_cls_model = model_sel_rand_search.train_fit_time(model,\n",
    "                                                                        param_grid,\n",
    "                                                                        transformer,\n",
    "                                                                        X_train,\n",
    "                                                                        X_test,\n",
    "                                                                        y_train,\n",
    "                                                                        y_test,\n",
    "                                                                        CV)\n",
    "\n",
    "# Pickle results\n",
    "with open('/Users/greenapple/project3/models/Dummy_30_cls_scores_params_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(Dummy_30_cls_scores_params, f)\n",
    "    \n",
    "# Pickle model\n",
    "with open('/Users/greenapple/project3/models/Dummy_30_cls_model_rand.pkl', 'wb') as f:\n",
    "    pickle.dump(Dummy_30_cls_scores_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:29.791703Z",
     "start_time": "2019-10-22T00:07:29.707075Z"
    }
   },
   "outputs": [],
   "source": [
    "Dummy_30_cls_scores_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:45.861782Z",
     "start_time": "2019-10-22T00:07:45.782856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dummy classifier\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "f1_dummy = f1_score(y_test, dummy.predict(X_test), average='micro')\n",
    "accuracy_dummy = accuracy_score(y_test, dummy.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T00:07:46.368892Z",
     "start_time": "2019-10-22T00:07:46.285594Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Dummy classifier F1 score: ', f1_dummy)\n",
    "print('Dummy classifier accuracy score: ', accuracy_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models. \n",
    "# MAKE THIS MORE EFFICIENT LATER\n",
    "model_fldr = '/Users/greenapple/project3/aws/models'\n",
    "\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg1_10_cls_model_rand.pkl'), 'rb')\n",
    "logreg1_10_cls_model_rand = pickle.load(pickling_out)\n",
    "pickling_out.close()\n",
    "\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg2_10_cls_model_rand.pkl'), 'rb')\n",
    "logreg2_10_cls_model_rand = pickle.load(pickling_out)\n",
    "pickling_out.close()\n",
    "\n",
    "pickling_out = open(os.path.join(model_fldr, 'logreg3_10_cls_model_rand.pkl'), 'rb')\n",
    "logreg3_10_cls_model_rand = pickle.load(pickling_out)\n",
    "pickling_out.close()\n",
    "\n",
    "pickling_out = open(os.path.join(model_fldr, 'KNN_10_cls_model_rand.pkl'), 'rb')\n",
    "KNN_10_cls_model_rand = pickle.load(pickling_out)\n",
    "pickling_out.close()\n",
    "\n",
    "pickling_out = open(os.path.join(model_fldr, 'NBmultinomial_10_cls_model_rand.pkl'), 'rb')\n",
    "NBmultinomial_10_cls_model_rand = pickle.load(pickling_out)\n",
    "pickling_out.close()\n",
    "\n",
    "pickling_out = open(os.path.join(model_fldr, 'RF_10_cls_model_rand.pkl'), 'rb')\n",
    "RF_10_cls_model_rand = pickle.load(pickling_out)\n",
    "pickling_out.close()\n",
    "\n",
    "pickling_out = open(os.path.join(model_fldr, 'GBM_10_cls_model_rand.pkl'), 'rb')\n",
    "GBM_10_cls_model_rand = pickle.load(pickling_out)\n",
    "pickling_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greenapple/anaconda3/envs/project3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['datetime', 'f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_formats = ['retina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T19:18:53.367743Z",
     "start_time": "2019-10-25T19:18:52.738791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "<class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "<class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "<class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "<class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "<class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
      "<class 'sklearn.model_selection._search.RandomizedSearchCV'>\n"
     ]
    }
   ],
   "source": [
    "# NEED TO BUILD THIS\n",
    "# Load models for ensembling\n",
    "\n",
    "model_fldr = '/Users/greenapple/project3/aws/models'\n",
    "\n",
    "file_dict = {\n",
    "    'logreg1_10_cls_model_rand':'logreg1_10_cls_model_rand.pkl',\n",
    "    'logreg2_10_cls_model_rand':'logreg2_10_cls_model_rand.pkl',\n",
    "    'logreg3_10_cls_model_rand':'logreg3_10_cls_model_rand.pkl',\n",
    "    'KNN_10_cls_model_rand':'KNN_10_cls_model_rand.pkl',\n",
    "    'NBmultinomial_10_cls_model_rand':'NBmultinomial_10_cls_model_rand.pkl',\n",
    "    'RF_10_cls_model_rand':'RF_10_cls_model_rand.pkl',\n",
    "    'GBM_10_cls_model_rand': 'GBM_10_cls_model_rand.pkl'\n",
    "}\n",
    "\n",
    "# Load models into memory\n",
    "for name, file in file_dict.items():\n",
    "    pickling_out = open(os.path.join(model_fldr, file), 'rb')\n",
    "    name = pickle.load(pickling_out)\n",
    "    pickling_out.close()\n",
    "    print(type(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T21:35:28.578090Z",
     "start_time": "2019-10-25T21:35:28.516576Z"
    }
   },
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    ('logreg3', logreg3_10_cls_model_rand),\n",
    "    ('KNN', KNN_10_cls_model_rand),\n",
    "    ('NBmultinomial', NBmultinomial_10_cls_model_rand),\n",
    "    ('RF', RF_10_cls_model_rand),\n",
    "    ('GBM', GBM_10_cls_model_rand)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T21:48:38.644476Z",
     "start_time": "2019-10-25T21:35:29.419505Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-55daa1e36b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m f1_train = cross_val_score(max_voting_classifer, \n\u001b[0;32m----> 9\u001b[0;31m             X_train, y_train, scoring='f1_micro', cv=5).mean()\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmax_voting_classifer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/ensemble/voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/sklearn/ensemble/voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 delayed(_parallel_fit_estimator)(clone(clf), X, y,\n\u001b[1;32m    100\u001b[0m                                                  sample_weight=sample_weight)\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclfs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'drop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             )\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/project3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Max voting classifier\n",
    "\n",
    "# Max voting classifier\n",
    "max_voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='hard',\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "max_voting_classifer.fit(X_train, y_train)\n",
    "y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "# f1_test_s = f1_score(y_test, y_hat, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T20:05:51.823086Z",
     "start_time": "2019-10-25T20:05:20.532Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_train, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average voting classifier\n",
    "average_voting_classifer = VotingClassifier(estimators=model_list,\n",
    "                                    voting='soft',\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "average_voting_classifer.fit(X_train, y_train)\n",
    "y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "# f1_test_s = f1_score(y_test, y_hat, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked classifier\n",
    "model = logreg_2_cls_model\n",
    "\n",
    "stacked_classifier = StackingClassifier(classifiers=model_list, \n",
    "                                        meta_classifier=model, \n",
    "                                        use_probas=False)\n",
    "\n",
    "\n",
    "f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "max_voting_classifer.fit(X_train, y_train)\n",
    "y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "# f1_test_s = f1_score(y_test, y_hat, average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of tuples onto a dictionary\n",
    "classifier_list = [x[1] for x in model_list]\n",
    "classifier_names = [x[0] for x in model_list]\n",
    "classifier_dict = dict(zip(classifier_names, classifier_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, classifier in classifier_dict.items():\n",
    "    \n",
    "    # Stacked classifier\n",
    "    model = classifier\n",
    "\n",
    "    stacked_classifier = StackingClassifier(classifiers=model_list, \n",
    "                                        meta_classifier=model, \n",
    "                                        use_probas=False)\n",
    "\n",
    "\n",
    "    f1_train = cross_val_score(max_voting_classifer, \n",
    "            X_train, y_train, scoring='f1_micro', cv=5).mean()\n",
    "\n",
    "    max_voting_classifer.fit(X_train, y_train)\n",
    "    y_hat = max_voting_classifer.predict(X_test) \n",
    "\n",
    "    f1_test = f1_score(y_test, y_hat, average='micro')\n",
    "    # f1_test_s = f1_score(y_test, y_hat, average='samples')\n",
    "    \n",
    "    print(name, f1_train, f1_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.986px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
